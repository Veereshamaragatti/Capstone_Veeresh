#!/usr/bin/env python3
"""
Enhanced Advanced Audio Processor with Live Subtitle Display
==========================================================

This enhanced version adds live subtitle functionality to display
the transcript synchronized with the video at the bottom.

Following the exact methodology:
FFmpeg ‚Üí Demucs ‚Üí Noisereduce ‚Üí PyDub ‚Üí Whisper ‚Üí MoviePy (with Subtitles)

Features:
- Complete audio noise removal pipeline
- Live subtitle display synchronized with audio
- Professional subtitle styling
- Automatic subtitle timing from Whisper transcription
- Fallback options for all components
"""

import os
import sys
import logging
import subprocess
import shutil
import tempfile
from pathlib import Path
from typing import Dict, Any, List, Tuple
import json

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

class AdvancedAudioProcessorWithSubtitles:
    """
    Advanced audio processor that follows the exact specified methodology
    with added live subtitle functionality.
    """
    
    def __init__(self, input_file: str, output_dir: str = "output"):
        self.input_file = Path(input_file)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # Create temporary directory for processing
        self.temp_dir = Path(tempfile.mkdtemp(prefix="advanced_audio_"))
        
        # File paths for each processing stage
        base_name = self.input_file.stem
        self.extracted_audio = self.temp_dir / f"extracted_{base_name}.wav"
        self.separated_vocals = self.temp_dir / f"vocals_{base_name}.wav"
        self.denoised_audio = self.temp_dir / f"denoised_{base_name}.wav"
        self.silence_trimmed_audio = self.temp_dir / f"trimmed_{base_name}.wav"
        self.transcript_file = self.output_dir / f"transcript_{base_name}.txt"
        self.srt_file = self.output_dir / f"subtitles_{base_name}.srt"
        self.final_video = self.output_dir / f"subtitled_{base_name}.mp4"
        
        # Track available tools
        self.available_tools = {
            'ffmpeg': self._check_ffmpeg(),
            'demucs': False,
            'noisereduce': False,
            'pydub': False,
            'whisper': False,
            'moviepy': False
        }
        
        # Store transcription data for subtitle generation
        self.transcription_data = None
        
        logger.info(f"Initialized Advanced Audio Processor with Subtitles")
        logger.info(f"Input: {self.input_file}")
        logger.info(f"Output Directory: {self.output_dir}")
        logger.info(f"Temporary Directory: {self.temp_dir}")
    
    def _check_ffmpeg(self) -> bool:
        """Check if FFmpeg is available."""
        try:
            result = subprocess.run(["ffmpeg", "-version"], 
                                  capture_output=True, text=True, timeout=10)
            return result.returncode == 0
        except:
            return False
    
    def _install_missing_dependencies(self):
        """Install missing Python dependencies automatically."""
        logger.info("Checking and installing required dependencies...")
        
        dependencies = [
            'demucs',
            'noisereduce', 
            'pydub',
            'openai-whisper',
            'moviepy',
            'torch',
            'librosa',
            'soundfile'
        ]
        
        for dep in dependencies:
            try:
                if dep == 'openai-whisper':
                    import whisper
                    self.available_tools['whisper'] = True
                elif dep == 'demucs':
                    try:
                        import demucs.api
                        self.available_tools['demucs'] = True
                    except ImportError:
                        try:
                            import demucs
                            self.available_tools['demucs'] = True
                        except ImportError:
                            pass
                elif dep == 'noisereduce':
                    import noisereduce
                    self.available_tools['noisereduce'] = True
                elif dep == 'pydub':
                    from pydub import AudioSegment
                    self.available_tools['pydub'] = True
                elif dep == 'moviepy':
                    import moviepy.editor
                    self.available_tools['moviepy'] = True
                else:
                    __import__(dep.replace('-', '_'))
            except ImportError:
                logger.info(f"Installing {dep}...")
                try:
                    subprocess.run([sys.executable, "-m", "pip", "install", dep], 
                                 check=True, capture_output=True)
                    logger.info(f"‚úì {dep} installed successfully")
                    
                    # Re-check availability
                    if dep == 'openai-whisper':
                        try:
                            import whisper
                            self.available_tools['whisper'] = True
                        except ImportError:
                            pass
                    elif dep == 'demucs':
                        try:
                            import demucs.api
                            self.available_tools['demucs'] = True
                        except ImportError:
                            try:
                                import demucs
                                self.available_tools['demucs'] = True
                            except ImportError:
                                pass
                    elif dep == 'noisereduce':
                        try:
                            import noisereduce
                            self.available_tools['noisereduce'] = True
                        except ImportError:
                            pass
                    elif dep == 'pydub':
                        try:
                            from pydub import AudioSegment
                            self.available_tools['pydub'] = True
                        except ImportError:
                            pass
                    elif dep == 'moviepy':
                        try:
                            import moviepy.editor
                            self.available_tools['moviepy'] = True
                        except ImportError:
                            pass
                        
                except subprocess.CalledProcessError as e:
                    logger.warning(f"Failed to install {dep}: {e}")
    
    def step1_audio_extraction_ffmpeg(self) -> bool:
        """Step 1: Extract high-quality audio using FFmpeg."""
        logger.info("STEP 1: AUDIO EXTRACTION (FFmpeg)")
        logger.info("="*60)
        
        if not self.available_tools['ffmpeg']:
            logger.error("FFmpeg not available")
            return False
        
        try:
            cmd = [
                "ffmpeg", "-i", str(self.input_file),
                "-vn", "-acodec", "pcm_s16le", "-ar", "44100", "-ac", "2",
                "-y", str(self.extracted_audio)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                logger.info(f"‚úì Audio extraction completed: {self.extracted_audio}")
                return True
            else:
                logger.error(f"‚úó Audio extraction failed: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"‚úó Audio extraction error: {str(e)}")
            return False
    
    def step2_noise_removal_demucs(self) -> bool:
        """Step 2: Advanced vocal separation using Demucs U-Net model."""
        logger.info("STEP 2: VOCAL SEPARATION (Demucs U-Net Model)")
        logger.info("="*60)
        
        if not self.available_tools['demucs']:
            logger.warning("Demucs not available, skipping vocal separation")
            shutil.copy2(self.extracted_audio, self.separated_vocals)
            return True
        
        try:
            import torch
            from demucs.api import Separator
            
            logger.info("Loading Demucs hybrid transformer model (htdemucs)...")
            logger.info("This may take several minutes for model download and processing...")
            
            # Initialize Demucs separator with hybrid transformer model
            separator = Separator(model="htdemucs", device="cpu")
            
            logger.info("Processing audio through Demucs U-Net architecture...")
            
            # Load and process audio
            import librosa
            import soundfile as sf
            
            audio, sr = librosa.load(str(self.extracted_audio), sr=None, mono=False)
            
            if audio.ndim == 1:
                audio = audio[None, :]  # Add channel dimension
            
            # Separate sources
            sources = separator.separate(torch.from_numpy(audio))
            
            # Extract vocals (index 3 in htdemucs)
            vocals = sources[3].numpy()  # vocals
            
            # Save separated vocals
            sf.write(str(self.separated_vocals), vocals.T, sr)
            
            logger.info(f"‚úì Demucs vocal separation completed: {self.separated_vocals}")
            return True
            
        except Exception as e:
            logger.warning(f"Demucs processing failed: {str(e)}")
            logger.info("Continuing with original audio...")
            shutil.copy2(self.extracted_audio, self.separated_vocals)
            return True
    
    def step3_noise_removal_noisereduce(self) -> bool:
        """Step 3: Spectral gating noise reduction using Noisereduce."""
        logger.info("STEP 3: SPECTRAL GATING NOISE REDUCTION (Noisereduce)")
        logger.info("="*60)
        
        if not self.available_tools['noisereduce']:
            logger.warning("Noisereduce not available, skipping spectral gating")
            shutil.copy2(self.separated_vocals, self.denoised_audio)
            return True
        
        try:
            import noisereduce as nr
            import librosa
            import soundfile as sf
            
            logger.info("Loading audio for spectral analysis...")
            
            # Load audio
            audio, sr = librosa.load(str(self.separated_vocals), sr=None)
            
            logger.info("Applying spectral gating algorithm...")
            
            # Apply noise reduction with spectral gating
            reduced_noise_audio = nr.reduce_noise(
                y=audio, 
                sr=sr,
                stationary=False,      # Handle non-stationary noise
                prop_decrease=0.8      # Reduce noise by 80%
            )
            
            # Save denoised audio
            sf.write(str(self.denoised_audio), reduced_noise_audio, sr)
            
            logger.info(f"‚úì Spectral gating completed: {self.denoised_audio}")
            return True
            
        except Exception as e:
            logger.warning(f"Noisereduce processing failed: {str(e)}")
            logger.info("Continuing with separated audio...")
            shutil.copy2(self.separated_vocals, self.denoised_audio)
            return True
    
    def step4_silence_handling_pydub(self) -> bool:
        """Step 4: Intelligent silence detection and handling using PyDub."""
        logger.info("STEP 4: SILENCE DETECTION AND HANDLING (PyDub)")
        logger.info("="*60)
        
        if not self.available_tools['pydub']:
            logger.warning("PyDub not available, skipping silence handling")
            shutil.copy2(self.denoised_audio, self.silence_trimmed_audio)
            return True
        
        try:
            from pydub import AudioSegment
            from pydub.silence import detect_nonsilent
            
            logger.info("Loading audio for silence analysis...")
            
            # Load audio
            audio = AudioSegment.from_wav(str(self.denoised_audio))
            original_duration = len(audio) / 1000.0  # Convert to seconds
            
            logger.info(f"Original duration: {original_duration:.2f}s")
            logger.info("Detecting silence intervals...")
            
            # Detect non-silent chunks
            nonsilent_ranges = detect_nonsilent(
                audio,
                min_silence_len=2000,   # Minimum 2 seconds of silence
                silence_thresh=-40      # Silence threshold in dBFS
            )
            
            if not nonsilent_ranges:
                logger.warning("No speech detected, keeping original audio")
                shutil.copy2(self.denoised_audio, self.silence_trimmed_audio)
                return True
            
            logger.info(f"Found {len(nonsilent_ranges)} non-speech intervals")
            
            # Combine non-silent chunks
            trimmed_audio = AudioSegment.empty()
            for start_ms, end_ms in nonsilent_ranges:
                trimmed_audio += audio[start_ms:end_ms]
            
            # Export trimmed audio
            trimmed_audio.export(str(self.silence_trimmed_audio), format="wav")
            
            final_duration = len(trimmed_audio) / 1000.0
            reduction_percent = ((original_duration - final_duration) / original_duration) * 100
            
            logger.info(f"‚úì Silence handling completed: {self.silence_trimmed_audio}")
            logger.info(f"‚úì Duration: {original_duration:.2f}s ‚Üí {final_duration:.2f}s")
            logger.info(f"‚úì Reduction: {reduction_percent:.1f}%")
            logger.info(f"‚úì Processed {len(nonsilent_ranges)} segments")
            
            return True
            
        except Exception as e:
            logger.warning(f"PyDub processing failed: {str(e)}")
            logger.info("Continuing with denoised audio...")
            shutil.copy2(self.denoised_audio, self.silence_trimmed_audio)
            return True
    
    def step5_speech_transcription_whisper(self) -> bool:
        """Step 5: Advanced speech recognition using OpenAI Whisper."""
        logger.info("STEP 5: SPEECH TRANSCRIPTION (OpenAI Whisper)")
        logger.info("="*60)
        
        if not self.available_tools['whisper']:
            logger.warning("Whisper not available")
            return self._create_basic_transcript()
        
        try:
            import whisper
            
            logger.info("Loading Whisper ASR model...")
            
            # Load Whisper model (base model for good balance of speed/accuracy)
            model = whisper.load_model("base")
            
            logger.info("Transcribing speech with word-level timestamps...")
            
            # Transcribe with word-level timestamps
            result = model.transcribe(
                str(self.silence_trimmed_audio),
                word_timestamps=True,
                language="en"  # Auto-detect if needed
            )
            
            # Store transcription data for subtitle generation
            self.transcription_data = result
            
            # Generate comprehensive transcript
            with open(self.transcript_file, 'w', encoding='utf-8') as f:
                f.write(f"Advanced Audio Processing Transcript\\n")
                f.write(f"Input: {self.input_file.name}\\n")
                f.write("=" * 60 + "\\n\\n")
                
                # Full transcript
                f.write("FULL TRANSCRIPT:\\n")
                f.write("-" * 20 + "\\n")
                f.write(result["text"].strip() + "\\n\\n")
                
                # Segment-level timestamps
                f.write("SEGMENT-LEVEL TIMESTAMPS:\\n")
                f.write("-" * 30 + "\\n")
                for segment in result["segments"]:
                    start_time = segment["start"]
                    end_time = segment["end"]
                    text = segment["text"].strip()
                    f.write(f"[{start_time:7.2f}s - {end_time:7.2f}s]: {text}\\n")
                
                # Summary statistics
                f.write(f"\\nTRANSCRIPT STATISTICS:\\n")
                f.write("-" * 25 + "\\n")
                f.write(f"Total Duration: {result.get('segments', [{}])[-1].get('end', 0):.2f} seconds\\n")
                f.write(f"Total Segments: {len(result['segments'])}\\n")
                f.write(f"Total Words: {len(result.get('words', []))}\\n")
            
            # Generate SRT subtitle file
            self._generate_srt_subtitles(result)
            
            logger.info(f"‚úì Whisper transcription completed: {self.transcript_file}")
            logger.info(f"‚úì SRT subtitles generated: {self.srt_file}")
            logger.info(f"‚úì Generated {len(result['segments'])} segments with word-level timestamps")
            
            return True
            
        except Exception as e:
            logger.error(f"‚úó Whisper transcription failed: {str(e)}")
            return self._create_basic_transcript()
    
    def _generate_srt_subtitles(self, transcription_data: Dict[Any, Any]) -> bool:
        """Generate SRT subtitle file from Whisper transcription."""
        try:
            with open(self.srt_file, 'w', encoding='utf-8') as f:
                for i, segment in enumerate(transcription_data["segments"], 1):
                    start_time = self._seconds_to_srt_time(segment["start"])
                    end_time = self._seconds_to_srt_time(segment["end"])
                    text = segment["text"].strip()
                    
                    f.write(f"{i}\\n")
                    f.write(f"{start_time} --> {end_time}\\n")
                    f.write(f"{text}\\n\\n")
            
            logger.info(f"‚úì SRT subtitles generated with {len(transcription_data['segments'])} entries")
            return True
            
        except Exception as e:
            logger.error(f"‚úó SRT generation failed: {str(e)}")
            return False
    
    def _seconds_to_srt_time(self, seconds: float) -> str:
        """Convert seconds to SRT time format (HH:MM:SS,mmm)."""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds - int(seconds)) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def _create_basic_transcript(self) -> bool:
        """Create basic transcript when Whisper is not available."""
        try:
            # Get audio duration for basic transcript
            if self.available_tools['ffmpeg']:
                cmd = ["ffprobe", "-v", "quiet", "-show_entries", "format=duration",
                       "-of", "csv=p=0", str(self.silence_trimmed_audio)]
                result = subprocess.run(cmd, capture_output=True, text=True)
                duration = float(result.stdout.strip()) if result.returncode == 0 else 0.0
            else:
                duration = 0.0
            
            with open(self.transcript_file, 'w', encoding='utf-8') as f:
                f.write(f"Basic Transcript\\n")
                f.write(f"Input: {self.input_file.name}\\n")
                f.write("=" * 60 + "\\n\\n")
                f.write("TRANSCRIPT:\\n")
                f.write("-" * 20 + "\\n")
                f.write("[Speech content - Whisper transcription not available]\\n\\n")
                f.write(f"Duration: {duration:.2f} seconds\\n")
            
            # Create basic SRT file
            with open(self.srt_file, 'w', encoding='utf-8') as f:
                f.write("1\\n")
                f.write("00:00:00,000 --> 00:01:00,000\\n")
                f.write("[Speech content - Automatic subtitles not available]\\n\\n")
            
            logger.info(f"‚úì Basic transcript created: {self.transcript_file}")
            return True
            
        except Exception as e:
            logger.error(f"‚úó Basic transcript creation failed: {str(e)}")
            return False
    
    def step6_output_synchronization_with_subtitles(self) -> bool:
        """Step 6: Create final video with cleaned audio and live subtitles."""
        logger.info("STEP 6: OUTPUT SYNCHRONIZATION WITH LIVE SUBTITLES (MoviePy/FFmpeg)")
        logger.info("="*60)
        
        # Try MoviePy first for advanced subtitle styling
        if self.available_tools['moviepy']:
            return self._create_subtitled_video_moviepy()
        else:
            logger.warning("MoviePy not available, falling back to FFmpeg subtitle embedding")
            return self._create_subtitled_video_ffmpeg()
    
    def _create_subtitled_video_moviepy(self) -> bool:
        """Create subtitled video using MoviePy with professional styling."""
        try:
            from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip
            
            logger.info("Loading original video...")
            video = VideoFileClip(str(self.input_file))
            
            logger.info("Loading cleaned and processed audio...")
            cleaned_audio = AudioFileClip(str(self.silence_trimmed_audio))
            
            logger.info("Creating synchronized subtitles...")
            
            # Create subtitle clips if transcription data is available
            subtitle_clips = []
            if self.transcription_data and "segments" in self.transcription_data:
                for segment in self.transcription_data["segments"]:
                    start_time = segment["start"]
                    end_time = segment["end"]
                    text = segment["text"].strip()
                    
                    if text:  # Only create clip if there's text
                        # Create subtitle clip with professional styling
                        subtitle_clip = TextClip(
                            text,
                            fontsize=24,
                            color='white',
                            font='Arial-Bold',
                            stroke_color='black',
                            stroke_width=2,
                            method='caption',
                            size=(video.w * 0.8, None),  # 80% of video width
                            align='center'
                        ).set_position(('center', 'bottom')).set_start(start_time).set_duration(end_time - start_time)
                        
                        subtitle_clips.append(subtitle_clip)
            
            logger.info(f"Created {len(subtitle_clips)} subtitle clips")
            
            # Combine video with cleaned audio
            video_with_audio = video.set_audio(cleaned_audio)
            
            # Composite video with subtitles
            if subtitle_clips:
                final_video = CompositeVideoClip([video_with_audio] + subtitle_clips)
            else:
                final_video = video_with_audio
            
            logger.info("Rendering final video with live subtitles...")
            logger.info("This may take several minutes depending on video length...")
            
            # Write final video
            final_video.write_videofile(
                str(self.final_video),
                codec='libx264',
                audio_codec='aac',
                verbose=False,
                logger=None,
                temp_audiofile='temp-audio.m4a',
                remove_temp=True
            )
            
            # Clean up
            for clip in subtitle_clips:
                clip.close()
            cleaned_audio.close()
            final_video.close()
            video_with_audio.close()
            video.close()
            
            logger.info(f"‚úì Subtitled video completed: {self.final_video}")
            logger.info("‚úì Professional subtitle styling applied")
            return True
            
        except Exception as e:
            logger.error(f"‚úó MoviePy subtitled video creation failed: {str(e)}")
            return self._create_subtitled_video_ffmpeg()
    
    def _create_subtitled_video_ffmpeg(self) -> bool:
        """Create subtitled video using FFmpeg with embedded SRT subtitles."""
        try:
            if not self.available_tools['ffmpeg']:
                logger.error("FFmpeg not available for subtitle embedding")
                return False
            
            logger.info("Embedding SRT subtitles using FFmpeg...")
            
            cmd = [
                "ffmpeg", 
                "-i", str(self.input_file),
                "-i", str(self.silence_trimmed_audio),
                "-i", str(self.srt_file),
                "-c:v", "libx264",
                "-c:a", "aac",
                "-c:s", "mov_text",  # Subtitle codec
                "-map", "0:v:0",    # Video from first input
                "-map", "1:a:0",    # Audio from second input  
                "-map", "2:s:0",    # Subtitles from third input
                "-shortest",
                "-y", str(self.final_video)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            if result.returncode == 0:
                logger.info(f"‚úì FFmpeg subtitled video completed: {self.final_video}")
                logger.info("‚úì SRT subtitles embedded in video")
                return True
            else:
                logger.error(f"‚úó FFmpeg subtitle embedding failed: {result.stderr}")
                # Fallback: create video without embedded subtitles
                return self._create_video_without_embedded_subtitles()
                
        except Exception as e:
            logger.error(f"‚úó FFmpeg subtitle embedding error: {str(e)}")
            return self._create_video_without_embedded_subtitles()
    
    def _create_video_without_embedded_subtitles(self) -> bool:
        """Fallback: create video with cleaned audio but external subtitles."""
        try:
            cmd = [
                "ffmpeg", "-i", str(self.input_file), "-i", str(self.silence_trimmed_audio),
                "-c:v", "copy", "-c:a", "aac",
                "-map", "0:v:0", "-map", "1:a:0",
                "-shortest", "-y", str(self.final_video)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            if result.returncode == 0:
                logger.info(f"‚úì Video with cleaned audio completed: {self.final_video}")
                logger.info(f"‚úì External subtitles available: {self.srt_file}")
                logger.info("‚ÑπÔ∏è  Load the SRT file in your video player for subtitles")
                return True
            else:
                logger.error(f"‚úó Video creation failed: {result.stderr}")
                return False
                
        except Exception as e:
            logger.error(f"‚úó Video creation error: {str(e)}")
            return False
    
    def process(self) -> bool:
        """Execute the complete advanced audio processing pipeline with subtitles."""
        logger.info("\\n" + "="*80)
        logger.info("ADVANCED AUDIO PROCESSOR WITH LIVE SUBTITLES")
        logger.info("Following Specified Methodology + Subtitle Generation")
        logger.info("="*80)
        
        # Install missing dependencies
        self._install_missing_dependencies()
        
        # Execute the enhanced 6-step methodology
        steps = [
            ("Audio Extraction (FFmpeg)", self.step1_audio_extraction_ffmpeg),
            ("Vocal Separation (Demucs)", self.step2_noise_removal_demucs),
            ("Spectral Gating (Noisereduce)", self.step3_noise_removal_noisereduce),
            ("Silence Handling (PyDub)", self.step4_silence_handling_pydub),
            ("Speech Transcription (Whisper)", self.step5_speech_transcription_whisper),
            ("Output + Live Subtitles (MoviePy)", self.step6_output_synchronization_with_subtitles)
        ]
        
        for i, (step_name, step_function) in enumerate(steps, 1):
            logger.info(f"\\nExecuting Step {i}: {step_name}")
            
            if not step_function():
                logger.error(f"‚ùå Failed at Step {i}: {step_name}")
                return False
                
            logger.info(f"‚úÖ Completed Step {i}: {step_name}")
        
        logger.info("\\n" + "="*80)
        logger.info("üéâ ADVANCED PIPELINE WITH SUBTITLES COMPLETED!")
        logger.info("="*80)
        logger.info(f"‚úì Enhanced Video with Live Subtitles: {self.final_video}")
        logger.info(f"‚úì External Subtitle File: {self.srt_file}")
        logger.info(f"‚úì Full Transcript: {self.transcript_file}")
        logger.info(f"‚úì Methodology: Demucs ‚Üí Noisereduce ‚Üí PyDub ‚Üí Whisper ‚Üí Subtitles")
        
        return True
    
    def cleanup_temp_files(self):
        """Remove temporary intermediate files."""
        logger.info("Cleaning up temporary files...")
        try:
            shutil.rmtree(self.temp_dir)
            logger.info("‚úì Temporary files cleaned up")
        except Exception as e:
            logger.warning(f"Could not clean up temp files: {e}")


def main():
    """Main function to execute the enhanced audio processing pipeline with subtitles."""
    input_video = "Unit-2 TA Session 1.mp4"
    output_directory = "output"
    
    # Verify input file exists
    if not Path(input_video).exists():
        logger.error(f"Input file not found: {input_video}")
        return False
    
    # Initialize enhanced processor
    processor = AdvancedAudioProcessorWithSubtitles(input_video, output_directory)
    
    try:
        # Execute the complete pipeline
        success = processor.process()
        
        if success:
            logger.info("\\nüéä ENHANCED PROCESSING COMPLETED SUCCESSFULLY!")
            logger.info("\\nResults:")
            logger.info(f"  üìπ Video with Live Subtitles: {processor.final_video}")
            logger.info(f"  üìù SRT Subtitle File: {processor.srt_file}")
            logger.info(f"  üìÑ Full Transcript: {processor.transcript_file}")
            logger.info("\\nFeatures Applied:")
            logger.info("  1. ‚úÖ Audio Extraction (FFmpeg)")
            logger.info("  2. ‚úÖ Vocal Separation (Demucs)")
            logger.info("  3. ‚úÖ Spectral Gating (Noisereduce)")
            logger.info("  4. ‚úÖ Silence Handling (PyDub)")
            logger.info("  5. ‚úÖ Speech Transcription (Whisper)")
            logger.info("  6. ‚úÖ Live Subtitle Generation (MoviePy/FFmpeg)")
            logger.info("\\nüé¨ Your video now has professional live subtitles!")
            logger.info("   The transcript appears synchronized at the bottom of the video.")
            
            # Cleanup option
            cleanup = input("\\nClean up temporary files? (y/n): ").lower().strip()
            if cleanup == 'y':
                processor.cleanup_temp_files()
        else:
            logger.error("‚ùå Processing failed. Check the logs above for details.")
        
        return success
        
    except KeyboardInterrupt:
        logger.info("Processing interrupted by user")
        return False
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}")
        return False


if __name__ == "__main__":
    main()
